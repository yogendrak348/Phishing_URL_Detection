{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNB_multi_url_detection",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx_J4Bsdu8xQ"
      },
      "source": [
        "import xlrd \n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "import pylab as plt\n",
        "\n",
        "\n",
        "\n",
        "# Setting Path of File and Initializing List:\n",
        "location = (\"UNB_multi_sep.xlsx\") \n",
        "list1 = []\n",
        "\n",
        "# Opening the Workbook and Defining Which Sheet to Use:\n",
        "wb = xlrd.open_workbook(location) \n",
        "sheet = wb.sheet_by_index(0) \n",
        "\n",
        "# Starting at Row 0 and Column 0:\n",
        "sheet.cell_value(0, 0)\n",
        "\n",
        "rows, cols = (165367, 9) \n",
        "\n",
        "# Iterating Over the Number of Rows and Appending to List:\n",
        "for i in range(0, rows):\n",
        "    list1.append(sheet.row_values(i))\n",
        "\n",
        "\n",
        "\n",
        "#maximum lengh of word in list in every row \n",
        "maxl = []\n",
        "for i in range(1,rows):\n",
        "    max1=0\n",
        "    for j in range(cols):\n",
        "        sr1=list1[i][j]\n",
        "        if(type(sr1)==float):\n",
        "          max1=1\n",
        "        elif(type(sr1)==int):\n",
        "          max1=1 \n",
        "        else:\n",
        "            ml1=len(list1[i][j])\n",
        "            if(ml1>max1):\n",
        "                max1=ml1 \n",
        "    maxl.append(max1)\n",
        "\n",
        "#length of domain name\n",
        "len_dom= []\n",
        "for i in range(1,rows):\n",
        "    sr1=list1[i][1]\n",
        "    ld1=0\n",
        "    if(type(sr1)==float):\n",
        "      ld1=len(str(sr1))\n",
        "    elif(type(sr1)==int):\n",
        "      ld1=len(str(sr1))\n",
        "    else:\n",
        "      ld1 = len(sr1) \n",
        "    len_dom.append(ld1)        \n",
        "\n",
        "#ip or domain\n",
        "ip_dom= []   \n",
        "for i in range(1,rows):\n",
        "    ur1=list1[i][0]\n",
        "    if(type(ur1)==float):\n",
        "        ip_dom.append(1)\n",
        "    else:\n",
        "        ip_dom.append(0)           \n",
        "    \n",
        "   \n",
        "# Setting Path of File and Initializing List:\n",
        "location = (\"UNB_multi_full.xlsx\") \n",
        "ful_list = []\n",
        "\n",
        "# Opening the Workbook and Defining Which Sheet to Use:\n",
        "wb = xlrd.open_workbook(location) \n",
        "sheet = wb.sheet_by_index(0) \n",
        "\n",
        "# Starting at Row 0 and Column 0:\n",
        "sheet.cell_value(0, 0)\n",
        "\n",
        "# Iterating Over the Number of Rows and Appending to List:\n",
        "for i in range(0, rows):\n",
        "    ful_list.append(sheet.row_values(i))\n",
        "\n",
        "dots=[]\n",
        "slash=[]\n",
        "spcl=[]\n",
        "exe=[]\n",
        "\n",
        "\n",
        "for i in range(1,rows):\n",
        "    dt = ful_list[i][0].count(\".\")\n",
        "    dots.append(dt)\n",
        "\n",
        "for i in range(1,rows):\n",
        "    ss = ful_list[i][0].count(\"/\")\n",
        "    slash.append(ss)\n",
        "\n",
        "for i in range(1,rows):\n",
        "    exe_count=0\n",
        "    ex = ful_list[i][0].count(\"exe\")\n",
        "    exe_count = exe_count+ex\n",
        "    ins = ful_list[i][0].count(\"install\")\n",
        "    exe_count = exe_count+ins\n",
        "    exe.append(exe_count)\n",
        "    \n",
        "tempt=[]    \n",
        "for i in range(1,rows):\n",
        "    temp_count=0\n",
        "    temp1 = ful_list[i][0].count(\"free\")\n",
        "    temp_count= temp_count+temp1\n",
        "    temp2 = ful_list[i][0].count(\"money\")\n",
        "    temp_count= temp_count+temp2\n",
        "    temp3 = ful_list[i][0].count(\"best\")\n",
        "    temp_count= temp_count+temp3\n",
        "    temp4 = ful_list[i][0].count(\"game\")\n",
        "    temp_count= temp_count+temp4\n",
        "    tempt.append(temp_count)\n",
        "\n",
        "https=[]\n",
        "for i in range(1,rows):\n",
        "    htt1 = ful_list[i][0].count(\"https\")\n",
        "    https.append(htt1)  \n",
        "\n",
        "htmlt=[]\n",
        "for i in range(1,rows):\n",
        "    ht_count=0\n",
        "    ht1=ful_list[i][0].count(\".htm\")\n",
        "    ht_count=ht_count+ht1\n",
        "    ht2=ful_list[i][0].count(\".html\")\n",
        "    ht_count=ht_count+ht2\n",
        "    htmlt.append(ht_count)\n",
        "\n",
        "php=[]\n",
        "for i in range(1,rows):\n",
        "    ph1 = ful_list[i][0].count(\".php\")\n",
        "    php.append(ph1)\n",
        "    \n",
        "com=[]\n",
        "for i in range(1,rows):\n",
        "    co1 = ful_list[i][0].count(\".com\")\n",
        "    com.append(co1)\n",
        "    \n",
        "gov=[]\n",
        "for i in range(1,rows):\n",
        "    go1 = ful_list[i][0].count(\".gov\")\n",
        "    gov.append(go1)\n",
        "    \n",
        "edu=[]\n",
        "for i in range(1,rows):\n",
        "    ed1 = ful_list[i][0].count(\".edu\")\n",
        "    edu.append(ed1)\n",
        "    \n",
        "org=[]\n",
        "for i in range(1,rows):\n",
        "    or1 = ful_list[i][0].count(\".org\")\n",
        "    org.append(or1)\n",
        "    \n",
        "text=[]\n",
        "for i in range(1,rows):\n",
        "    tx = ful_list[i][0].count(\".txt\")\n",
        "    text.append(tx)\n",
        "\n",
        "net=[]\n",
        "for i in range(1,rows):\n",
        "    nt = ful_list[i][0].count(\".net\")\n",
        "    net.append(nt)\n",
        "\n",
        "info=[]\n",
        "for i in range(1,rows):\n",
        "    inf = ful_list[i][0].count(\".info\")\n",
        "    info.append(inf)\n",
        "    \n",
        "js=[]\n",
        "for i in range(1,rows):    \n",
        "    js1 = ful_list[i][0].count(\".js\")\n",
        "    js.append(js1)\n",
        "    \n",
        "offens=[]\n",
        "for i in range(1,rows): \n",
        "    offens_count=0\n",
        "    off1 = ful_list[i][0].count(\"girl\")\n",
        "    offens_count=offens_count+off1\n",
        "    off2 = ful_list[i][0].count(\"hot\")\n",
        "    offens_count=offens_count+off2\n",
        "    off3 = ful_list[i][0].count(\"nude\")\n",
        "    offens_count=offens_count+off3\n",
        "    off4 = ful_list[i][0].count(\"ball\")\n",
        "    offens_count=offens_count+off4\n",
        "    off5 = ful_list[i][0].count(\"sex\")\n",
        "    offens_count=offens_count+off5\n",
        "    off6 = ful_list[i][0].count(\"fuck\")\n",
        "    offens_count=offens_count+off6\n",
        "    off7 = ful_list[i][0].count(\"xx\")\n",
        "    offens_count=offens_count+off7\n",
        "    offens.append(offens_count)\n",
        "\n",
        "qs_mark=[]\n",
        "for i in range(1,rows):    \n",
        "    qs = ful_list[i][0].count(\"?\")\n",
        "    qs_mark.append(qs)\n",
        "    \n",
        "    \n",
        "for i in range(1,rows):\n",
        "    sp_count=0\n",
        "    sp1=ful_list[i][0].count(\"@\")\n",
        "    sp_count=sp_count+sp1\n",
        "    sp2=ful_list[i][0].count(\"_\")\n",
        "    sp_count=sp_count+sp2\n",
        "    sp3=ful_list[i][0].count(\"=\")\n",
        "    sp_count=sp_count+sp3\n",
        "    sp4=ful_list[i][0].count(\"#\")\n",
        "    sp_count=sp_count+sp4\n",
        "    sp5=ful_list[i][0].count(\"&\")\n",
        "    sp_count=sp_count+sp5\n",
        "    sp6=ful_list[i][0].count(\"!\")\n",
        "    sp_count=sp_count+sp6\n",
        "    sp7=ful_list[i][0].count(\"$\")\n",
        "    sp_count=sp_count+sp7\n",
        "    sp8=ful_list[i][0].count(\"%\")\n",
        "    sp_count=sp_count+sp8\n",
        "    sp9=ful_list[i][0].count(\"^\")\n",
        "    sp_count=sp_count+sp9\n",
        "    sp10=ful_list[i][0].count(\"*\")\n",
        "    sp_count=sp_count+sp10\n",
        "    sp11=ful_list[i][0].count(\"^\")\n",
        "    sp_count=sp_count+sp11\n",
        "    sp12=ful_list[i][0].count(\"*\")\n",
        "    sp_count=sp_count+sp12\n",
        "    sp13=ful_list[i][0].count(\"-\")\n",
        "    sp_count=sp_count+sp13\n",
        "    sp14=ful_list[i][0].count(\"+\")\n",
        "    sp_count=sp_count+sp14\n",
        "    spcl.append(sp_count)\n",
        "\n",
        "watch=[]\n",
        "for i in range(1,rows):\n",
        "    wat = ful_list[i][0].count(\"watch\")\n",
        "    watch.append(wat)\n",
        "    \n",
        "youtube=[]\n",
        "for i in range(1,rows):\n",
        "    you = ful_list[i][0].count(\"youtube\")\n",
        "    youtube.append(you)\n",
        "    \n",
        "image=[]\n",
        "for i in range(1,rows):\n",
        "    ima = ful_list[i][0].count(\"image\")\n",
        "    image.append(ima)\n",
        "\n",
        "login_upload=[]\n",
        "for i in range(1,rows): \n",
        "    login_count=0\n",
        "    log1 = ful_list[i][0].count(\"login\")\n",
        "    login_count=login_count+log1\n",
        "    log2 = ful_list[i][0].count(\"upload\")\n",
        "    login_count=login_count+log2\n",
        "    login_upload.append(login_count)\n",
        "    \n",
        "# no of digits count\n",
        "num_count=[]\n",
        "for i in range(1,rows):\n",
        "    digi=alfa=0\n",
        "    ulstr=ful_list[i][0]\n",
        "    for c in ulstr:\n",
        "        if c.isdigit():\n",
        "            digi=digi+1\n",
        "        else:\n",
        "            pass\n",
        "    num_count.append(digi)\n",
        "    \n",
        "url_len=[]\n",
        "for i in range(1,rows):\n",
        "    ul = len(ful_list[i][0])\n",
        "    url_len.append(ul)     \n",
        "\n",
        "#class values    \n",
        "url_class = []\n",
        "for i in range(1,rows):\n",
        "    url_cls = ful_list[i][1]\n",
        "    if(url_cls=='benign'): \n",
        "        url_class.append(1)\n",
        "    elif(url_cls=='phishing'): \n",
        "        url_class.append(2)\n",
        "    elif(url_cls=='malware'): \n",
        "        url_class.append(3)\n",
        "    elif(url_cls=='spam'): \n",
        "        url_class.append(4)\n",
        "    else:\n",
        "        url_class.append(5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyAAtCXeoC-f",
        "outputId": "c2fcd9dc-c3f4-4368-b11b-99b1826c1f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#dataframe\n",
        "data=pd.DataFrame(\n",
        "    {'url_len': url_len,\n",
        "     'maxw_len': maxl,\n",
        "     'dots': dots,\n",
        "     'domain_len' : len_dom,\n",
        "     'numeric_count': num_count,\n",
        "     'no_/' : slash,\n",
        "     'spcl_char': spcl,\n",
        "     '.exe_install': exe,\n",
        "     '.com': com,\n",
        "     '.php': php,\n",
        "     '.gov': gov,\n",
        "     '.org': org,\n",
        "     '.edu': edu,\n",
        "     'https': https,\n",
        "     '.htm_html': htmlt,\n",
        "     #'.txt': text,\n",
        "     '.net': net,\n",
        "     '.info': info,\n",
        "     '.js': js,\n",
        "     'q_?': qs_mark,\n",
        "     'tempt_word' : tempt,\n",
        "     'offensive': offens,\n",
        "     #'watch': watch,\n",
        "     #'youtube': youtube,\n",
        "     'image': image,\n",
        "     'login_upload' :login_upload,\n",
        "     'IP' : ip_dom,\n",
        "     'URL_Class': url_class\n",
        "     \n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data_shape=data.shape\n",
        "print(data_shape)\n",
        "\n",
        "\n",
        "X = data.iloc[:, 0:(data_shape[1]-1)].values\n",
        "y = data.iloc[:, (data_shape[1]-1)].values\n",
        "\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.fit_transform(x_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(165366, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdQqztfuIR5U",
        "outputId": "0ef852ef-01c6-4c08-accd-bfc4fd5863e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "#KNN\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "#target_names = ['True', 'False']\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Creating the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9719417064763863\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.99      0.98      6972\n",
            "           2       0.94      0.78      0.85      2075\n",
            "           3       0.95      0.96      0.96      2301\n",
            "           4       0.96      0.97      0.97      2325\n",
            "           5       0.97      0.99      0.98     19401\n",
            "\n",
            "    accuracy                           0.97     33074\n",
            "   macro avg       0.96      0.94      0.95     33074\n",
            "weighted avg       0.97      0.97      0.97     33074\n",
            "\n",
            "[[ 6881     7    26     8    50]\n",
            " [   39  1621    36    27   352]\n",
            " [   23    27  2213     5    33]\n",
            " [    5     7     3  2251    59]\n",
            " [   65    68    41    47 19180]]\n",
            "Accuracy: 0.9719417064763863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO7PUpMDis52"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "import zlib\n",
        "import itertools\n",
        "import sklearn\n",
        "import itertools\n",
        "import scipy\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import models, layers, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.utils import class_weight\n",
        "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "#from keras.applications.mobilenet import MobileNet\n",
        "#from sklearn.metrics import roc_auc_score\n",
        "#from sklearn.metrics import roc_curve\n",
        "#from sklearn.metrics import auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA-CcTGikRl-"
      },
      "source": [
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "\n",
        "encoder.fit(y_train)\n",
        "encoded_Ytrain = encoder.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dy_train = np_utils.to_categorical(encoded_Ytrain)\n",
        "\n",
        "encoder.fit(y_test)\n",
        "encoded_Ytest = encoder.transform(y_test)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dy_test = np_utils.to_categorical(encoded_Ytest)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De0yNSpRjwfP",
        "outputId": "4596cc31-eba4-4816-e53b-8e1ce1c6bab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "optimizer1=keras.optimizers.Adam(lr=0.002)\n",
        "#create model\n",
        "model = Sequential()\n",
        "\n",
        "#get number of columns in training data\n",
        "n_cols = x_train.shape[1]\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "#set early stopping monitor so the model stops training when it won't improve anymore\n",
        "early_stopping_monitor = EarlyStopping(patience=10)\n",
        "\n",
        "\n",
        "#create model\n",
        "model_mc = Sequential()\n",
        "\n",
        "#add model layers\n",
        "model_mc.add(Dense(27, activation='relu', input_shape=(n_cols,)))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(5, activation='softmax'))\n",
        "\n",
        "#compile model using mse as a measure of model performance\n",
        "model_mc.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "#train model\n",
        "model_mc.fit(x_train, dy_train, validation_split=0.2, epochs=300, callbacks=[early_stopping_monitor])\n",
        "#model_mc.fit(x_train, y_train, validation_split=0.2, epochs=30)\n",
        "\n",
        "model_mc.summary()\n",
        "\n",
        "\n",
        "y_pred = model_mc.predict(x_test)\n",
        "Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
        "Y_true = np.argmax(dy_test,axis = 1) \n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Y_true, Y_pred_classes))\n",
        "\n",
        "#target_names = ['True', 'False']\n",
        "print(classification_report(Y_true, Y_pred_classes))\n",
        "\n",
        "\n",
        "print(confusion_matrix(Y_true, Y_pred_classes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0382 - accuracy: 0.8787 - val_loss: 0.0288 - val_accuracy: 0.9074\n",
            "Epoch 2/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0250 - accuracy: 0.9224 - val_loss: 0.0230 - val_accuracy: 0.9303\n",
            "Epoch 3/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0217 - accuracy: 0.9332 - val_loss: 0.0196 - val_accuracy: 0.9403\n",
            "Epoch 4/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0196 - accuracy: 0.9397 - val_loss: 0.0184 - val_accuracy: 0.9438\n",
            "Epoch 5/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0184 - accuracy: 0.9443 - val_loss: 0.0193 - val_accuracy: 0.9411\n",
            "Epoch 6/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0175 - accuracy: 0.9469 - val_loss: 0.0175 - val_accuracy: 0.9464\n",
            "Epoch 7/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0170 - accuracy: 0.9488 - val_loss: 0.0176 - val_accuracy: 0.9457\n",
            "Epoch 8/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0163 - accuracy: 0.9508 - val_loss: 0.0176 - val_accuracy: 0.9460\n",
            "Epoch 9/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0157 - accuracy: 0.9529 - val_loss: 0.0158 - val_accuracy: 0.9532\n",
            "Epoch 10/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0153 - accuracy: 0.9538 - val_loss: 0.0152 - val_accuracy: 0.9536\n",
            "Epoch 11/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0148 - accuracy: 0.9555 - val_loss: 0.0150 - val_accuracy: 0.9543\n",
            "Epoch 12/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0144 - accuracy: 0.9566 - val_loss: 0.0163 - val_accuracy: 0.9516\n",
            "Epoch 13/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0140 - accuracy: 0.9583 - val_loss: 0.0166 - val_accuracy: 0.9506\n",
            "Epoch 14/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0140 - accuracy: 0.9582 - val_loss: 0.0141 - val_accuracy: 0.9572\n",
            "Epoch 15/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0136 - accuracy: 0.9595 - val_loss: 0.0139 - val_accuracy: 0.9583\n",
            "Epoch 16/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0136 - accuracy: 0.9593 - val_loss: 0.0145 - val_accuracy: 0.9566\n",
            "Epoch 17/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0133 - accuracy: 0.9606 - val_loss: 0.0137 - val_accuracy: 0.9584\n",
            "Epoch 18/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0130 - accuracy: 0.9615 - val_loss: 0.0128 - val_accuracy: 0.9621\n",
            "Epoch 19/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0129 - accuracy: 0.9618 - val_loss: 0.0130 - val_accuracy: 0.9607\n",
            "Epoch 20/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0128 - accuracy: 0.9624 - val_loss: 0.0134 - val_accuracy: 0.9606\n",
            "Epoch 21/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0128 - accuracy: 0.9626 - val_loss: 0.0130 - val_accuracy: 0.9616\n",
            "Epoch 22/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0126 - accuracy: 0.9630 - val_loss: 0.0147 - val_accuracy: 0.9562\n",
            "Epoch 23/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0124 - accuracy: 0.9632 - val_loss: 0.0134 - val_accuracy: 0.9594\n",
            "Epoch 24/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0125 - accuracy: 0.9628 - val_loss: 0.0132 - val_accuracy: 0.9607\n",
            "Epoch 25/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0121 - accuracy: 0.9643 - val_loss: 0.0129 - val_accuracy: 0.9613\n",
            "Epoch 26/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0121 - accuracy: 0.9643 - val_loss: 0.0125 - val_accuracy: 0.9641\n",
            "Epoch 27/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0119 - accuracy: 0.9653 - val_loss: 0.0123 - val_accuracy: 0.9644\n",
            "Epoch 28/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0119 - accuracy: 0.9648 - val_loss: 0.0128 - val_accuracy: 0.9621\n",
            "Epoch 29/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0118 - accuracy: 0.9650 - val_loss: 0.0126 - val_accuracy: 0.9636\n",
            "Epoch 30/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0119 - accuracy: 0.9650 - val_loss: 0.0127 - val_accuracy: 0.9628\n",
            "Epoch 31/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0116 - accuracy: 0.9659 - val_loss: 0.0133 - val_accuracy: 0.9611\n",
            "Epoch 32/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0115 - accuracy: 0.9660 - val_loss: 0.0127 - val_accuracy: 0.9630\n",
            "Epoch 33/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0114 - accuracy: 0.9667 - val_loss: 0.0129 - val_accuracy: 0.9611\n",
            "Epoch 34/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0113 - accuracy: 0.9666 - val_loss: 0.0125 - val_accuracy: 0.9634\n",
            "Epoch 35/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0112 - accuracy: 0.9672 - val_loss: 0.0123 - val_accuracy: 0.9640\n",
            "Epoch 36/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0112 - accuracy: 0.9670 - val_loss: 0.0131 - val_accuracy: 0.9602\n",
            "Epoch 37/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0112 - accuracy: 0.9668 - val_loss: 0.0133 - val_accuracy: 0.9616\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 27)                675       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                896       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 4,904\n",
            "Trainable params: 4,904\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.9617524339360223\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      6972\n",
            "           1       0.86      0.78      0.82      2075\n",
            "           2       0.94      0.91      0.93      2301\n",
            "           3       0.98      0.93      0.95      2325\n",
            "           4       0.97      0.98      0.97     19401\n",
            "\n",
            "    accuracy                           0.96     33074\n",
            "   macro avg       0.94      0.92      0.93     33074\n",
            "weighted avg       0.96      0.96      0.96     33074\n",
            "\n",
            "[[ 6901    16    15     4    36]\n",
            " [   30  1625    63    21   336]\n",
            " [   57    35  2100     5   104]\n",
            " [    6    26     8  2157   128]\n",
            " [  119   181    50    25 19026]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrSC8Um3MfTj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsG771nlgp3l",
        "outputId": "595e6c61-d654-407d-a5f1-a367bcfc38cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        " \n",
        "\n",
        "logmodel = LogisticRegression()\n",
        "logmodel.fit(x_train, y_train)\n",
        " \n",
        "predictions = logmodel.predict(x_test)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.87      0.85      6972\n",
            "           2       0.80      0.40      0.53      2075\n",
            "           3       0.82      0.51      0.63      2301\n",
            "           4       0.73      0.73      0.73      2325\n",
            "           5       0.87      0.94      0.91     19401\n",
            "\n",
            "    accuracy                           0.85     33074\n",
            "   macro avg       0.81      0.69      0.73     33074\n",
            "weighted avg       0.85      0.85      0.84     33074\n",
            "\n",
            "[[ 6067    11    77    95   722]\n",
            " [  145   823    58   168   881]\n",
            " [  449    92  1168    53   539]\n",
            " [   66     1     2  1686   570]\n",
            " [  550   102   119   318 18312]]\n",
            "0.8482796154078732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz6ul-mWhzQD",
        "outputId": "e6ebe2e9-df0a-4fe4-ba07-33f2db77cae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clf=RandomForestClassifier(n_estimators=20)\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "#target_names = ['True', 'False']\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Creating the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      1.00      0.99      6972\n",
            "           2       0.95      0.79      0.87      2075\n",
            "           3       0.99      0.97      0.98      2301\n",
            "           4       0.98      0.97      0.97      2325\n",
            "           5       0.97      0.99      0.98     19401\n",
            "\n",
            "    accuracy                           0.98     33074\n",
            "   macro avg       0.98      0.94      0.96     33074\n",
            "weighted avg       0.98      0.98      0.98     33074\n",
            "\n",
            "Accuracy: 0.9775352240430549\n",
            "[[ 6940     2     2     1    27]\n",
            " [   17  1642     7     7   402]\n",
            " [   13    13  2232     0    43]\n",
            " [    1    11     1  2248    64]\n",
            " [   32    52     5    43 19269]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ut_Q9BgNGMW",
        "outputId": "3ff0a1fa-081c-4e30-eccc-32429b3c27c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Gaussian Kernel\n",
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(x_train, y_train)\n",
        "y_pred = svclassifier.predict(x_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9286750922174518\n",
            "[[ 6815    13    16    16   112]\n",
            " [   41  1153    28    24   829]\n",
            " [  194    65  1713    35   294]\n",
            " [   17     8     2  1978   320]\n",
            " [  211    58    20    56 19056]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.94      0.98      0.96      6972\n",
            "           2       0.89      0.56      0.68      2075\n",
            "           3       0.96      0.74      0.84      2301\n",
            "           4       0.94      0.85      0.89      2325\n",
            "           5       0.92      0.98      0.95     19401\n",
            "\n",
            "    accuracy                           0.93     33074\n",
            "   macro avg       0.93      0.82      0.86     33074\n",
            "weighted avg       0.93      0.93      0.92     33074\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iVKKn3cOmQW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX7WM-8mcm3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}