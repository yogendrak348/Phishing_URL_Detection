{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNB_binary_url_detection",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx_J4Bsdu8xQ",
        "outputId": "c2f35dae-94f7-4358-b36f-a2fc30a23514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import xlrd \n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "import pylab as plt\n",
        "\n",
        "\n",
        "\n",
        "# Setting Path of File and Initializing List:\n",
        "location = (\"UNB_binary_sep.xlsx\") \n",
        "list1 = []\n",
        "\n",
        "# Opening the Workbook and Defining Which Sheet to Use:\n",
        "wb = xlrd.open_workbook(location) \n",
        "sheet = wb.sheet_by_index(0) \n",
        "\n",
        "# Starting at Row 0 and Column 0:\n",
        "sheet.cell_value(0, 0)\n",
        "\n",
        "rows, cols = (165367, 10) \n",
        "\n",
        "# Iterating Over the Number of Rows and Appending to List:\n",
        "for i in range(0, rows):\n",
        "    list1.append(sheet.row_values(i))\n",
        "\n",
        "\n",
        "\n",
        "#maximum lengh of word in list in every row \n",
        "maxl = []\n",
        "for i in range(1,rows):\n",
        "    max1=0\n",
        "    for j in range(cols):\n",
        "        sr1=list1[i][j]\n",
        "        if(type(sr1)==float):\n",
        "          max1=1\n",
        "        elif(type(sr1)==int):\n",
        "          max1=1\n",
        "        else:\n",
        "            ml1=len(list1[i][j])\n",
        "            if(ml1>max1):\n",
        "                max1=ml1 \n",
        "    maxl.append(max1)\n",
        "\n",
        "#length of domain name\n",
        "len_dom= []\n",
        "for i in range(1,rows):\n",
        "    sr1=list1[i][1]\n",
        "    ld1=0\n",
        "    if(type(sr1)==float):\n",
        "      ld1=len(str(sr1))\n",
        "    elif(type(sr1)==int):\n",
        "      ld1=len(str(sr1))\n",
        "    else:\n",
        "      ld1 = len(sr1) \n",
        "    len_dom.append(ld1)        \n",
        "\n",
        "#ip or domain\n",
        "ip_dom= []   \n",
        "for i in range(1,rows):\n",
        "    ur1=list1[i][0]\n",
        "    if(type(ur1)==float):\n",
        "        ip_dom.append(1)\n",
        "    else:\n",
        "        ip_dom.append(0)           \n",
        "       \n",
        "# Setting Path of File and Initializing List:\n",
        "location = (\"UNB_binary_full.xlsx\") \n",
        "ful_list = []\n",
        "\n",
        "# Opening the Workbook and Defining Which Sheet to Use:\n",
        "wb = xlrd.open_workbook(location) \n",
        "sheet = wb.sheet_by_index(0) \n",
        "\n",
        "# Starting at Row 0 and Column 0:\n",
        "sheet.cell_value(0, 0)\n",
        "\n",
        "# Iterating Over the Number of Rows and Appending to List:\n",
        "for i in range(0, rows):\n",
        "    ful_list.append(sheet.row_values(i))\n",
        "\n",
        "dots=[]\n",
        "slash=[]\n",
        "spcl=[]\n",
        "exe=[]\n",
        "\n",
        "\n",
        "for i in range(1,rows):\n",
        "    dt = ful_list[i][0].count(\".\")\n",
        "    dots.append(dt)\n",
        "\n",
        "for i in range(1,rows):\n",
        "    ss = ful_list[i][0].count(\"/\")\n",
        "    slash.append(ss)\n",
        "\n",
        "for i in range(1,rows):\n",
        "    exe_count=0\n",
        "    ex = ful_list[i][0].count(\"exe\")\n",
        "    exe_count = exe_count+ex\n",
        "    ins = ful_list[i][0].count(\"install\")\n",
        "    exe_count = exe_count+ins\n",
        "    exe.append(exe_count)\n",
        "    \n",
        "tempt=[]    \n",
        "for i in range(1,rows):\n",
        "    temp_count=0\n",
        "    temp1 = ful_list[i][0].count(\"free\")\n",
        "    temp_count= temp_count+temp1\n",
        "    temp2 = ful_list[i][0].count(\"money\")\n",
        "    temp_count= temp_count+temp2\n",
        "    temp3 = ful_list[i][0].count(\"best\")\n",
        "    temp_count= temp_count+temp3\n",
        "    temp4 = ful_list[i][0].count(\"game\")\n",
        "    temp_count= temp_count+temp4\n",
        "    tempt.append(temp_count)\n",
        "\n",
        "https=[]\n",
        "for i in range(1,rows):\n",
        "    htt1 = ful_list[i][0].count(\"https\")\n",
        "    https.append(htt1)  \n",
        "\n",
        "htmlt=[]\n",
        "for i in range(1,rows):\n",
        "    ht_count=0\n",
        "    ht1=ful_list[i][0].count(\".htm\")\n",
        "    ht_count=ht_count+ht1\n",
        "    ht2=ful_list[i][0].count(\".html\")\n",
        "    ht_count=ht_count+ht2\n",
        "    htmlt.append(ht_count)\n",
        "\n",
        "php=[]\n",
        "for i in range(1,rows):\n",
        "    ph1 = ful_list[i][0].count(\".php\")\n",
        "    php.append(ph1)\n",
        "    \n",
        "com=[]\n",
        "for i in range(1,rows):\n",
        "    co1 = ful_list[i][0].count(\".com\")\n",
        "    com.append(co1)\n",
        "    \n",
        "gov=[]\n",
        "for i in range(1,rows):\n",
        "    go1 = ful_list[i][0].count(\".gov\")\n",
        "    gov.append(go1)\n",
        "    \n",
        "edu=[]\n",
        "for i in range(1,rows):\n",
        "    ed1 = ful_list[i][0].count(\".edu\")\n",
        "    edu.append(ed1)\n",
        "    \n",
        "org=[]\n",
        "for i in range(1,rows):\n",
        "    or1 = ful_list[i][0].count(\".org\")\n",
        "    org.append(or1)\n",
        "    \n",
        "text=[]\n",
        "for i in range(1,rows):\n",
        "    tx = ful_list[i][0].count(\".txt\")\n",
        "    text.append(tx)\n",
        "\n",
        "net=[]\n",
        "for i in range(1,rows):\n",
        "    nt = ful_list[i][0].count(\".net\")\n",
        "    net.append(nt)\n",
        "\n",
        "info=[]\n",
        "for i in range(1,rows):\n",
        "    inf = ful_list[i][0].count(\".info\")\n",
        "    info.append(inf)\n",
        "    \n",
        "js=[]\n",
        "for i in range(1,rows):    \n",
        "    js1 = ful_list[i][0].count(\".js\")\n",
        "    js.append(js1)\n",
        "    \n",
        "offens=[]\n",
        "for i in range(1,rows): \n",
        "    offens_count=0\n",
        "    off1 = ful_list[i][0].count(\"girl\")\n",
        "    offens_count=offens_count+off1\n",
        "    off2 = ful_list[i][0].count(\"hot\")\n",
        "    offens_count=offens_count+off2\n",
        "    off3 = ful_list[i][0].count(\"nude\")\n",
        "    offens_count=offens_count+off3\n",
        "    off4 = ful_list[i][0].count(\"ball\")\n",
        "    offens_count=offens_count+off4\n",
        "    off5 = ful_list[i][0].count(\"sex\")\n",
        "    offens_count=offens_count+off5\n",
        "    off6 = ful_list[i][0].count(\"fuck\")\n",
        "    offens_count=offens_count+off6\n",
        "    off7 = ful_list[i][0].count(\"xx\")\n",
        "    offens_count=offens_count+off7\n",
        "    offens.append(offens_count)\n",
        "\n",
        "qs_mark=[]\n",
        "for i in range(1,rows):    \n",
        "    qs = ful_list[i][0].count(\"?\")\n",
        "    qs_mark.append(qs)\n",
        "    \n",
        "    \n",
        "for i in range(1,rows):\n",
        "    sp_count=0\n",
        "    sp1=ful_list[i][0].count(\"@\")\n",
        "    sp_count=sp_count+sp1\n",
        "    sp2=ful_list[i][0].count(\"_\")\n",
        "    sp_count=sp_count+sp2\n",
        "    sp3=ful_list[i][0].count(\"=\")\n",
        "    sp_count=sp_count+sp3\n",
        "    sp4=ful_list[i][0].count(\"#\")\n",
        "    sp_count=sp_count+sp4\n",
        "    sp5=ful_list[i][0].count(\"&\")\n",
        "    sp_count=sp_count+sp5\n",
        "    sp6=ful_list[i][0].count(\"!\")\n",
        "    sp_count=sp_count+sp6\n",
        "    sp7=ful_list[i][0].count(\"$\")\n",
        "    sp_count=sp_count+sp7\n",
        "    sp8=ful_list[i][0].count(\"%\")\n",
        "    sp_count=sp_count+sp8\n",
        "    sp9=ful_list[i][0].count(\"^\")\n",
        "    sp_count=sp_count+sp9\n",
        "    sp10=ful_list[i][0].count(\"*\")\n",
        "    sp_count=sp_count+sp10\n",
        "    sp11=ful_list[i][0].count(\"^\")\n",
        "    sp_count=sp_count+sp11\n",
        "    sp12=ful_list[i][0].count(\"*\")\n",
        "    sp_count=sp_count+sp12\n",
        "    sp13=ful_list[i][0].count(\"-\")\n",
        "    sp_count=sp_count+sp13\n",
        "    sp14=ful_list[i][0].count(\"+\")\n",
        "    sp_count=sp_count+sp14\n",
        "    spcl.append(sp_count)\n",
        "\n",
        "watch=[]\n",
        "for i in range(1,rows):\n",
        "    wat = ful_list[i][0].count(\"watch\")\n",
        "    watch.append(wat)\n",
        "    \n",
        "youtube=[]\n",
        "for i in range(1,rows):\n",
        "    you = ful_list[i][0].count(\"youtube\")\n",
        "    youtube.append(you)\n",
        "    \n",
        "image=[]\n",
        "for i in range(1,rows):\n",
        "    ima = ful_list[i][0].count(\"image\")\n",
        "    image.append(ima)\n",
        "\n",
        "login_upload=[]\n",
        "for i in range(1,rows): \n",
        "    login_count=0\n",
        "    log1 = ful_list[i][0].count(\"login\")\n",
        "    login_count=login_count+log1\n",
        "    log2 = ful_list[i][0].count(\"upload\")\n",
        "    login_count=login_count+log2\n",
        "    login_upload.append(login_count)\n",
        "    \n",
        "# no of digits count\n",
        "num_count=[]\n",
        "for i in range(1,rows):\n",
        "    digi=alfa=0\n",
        "    ulstr=ful_list[i][0]\n",
        "    for c in ulstr:\n",
        "        if c.isdigit():\n",
        "            digi=digi+1\n",
        "        else:\n",
        "            pass\n",
        "    num_count.append(digi)\n",
        "    \n",
        "url_len=[]\n",
        "for i in range(1,rows):\n",
        "    ul = len(ful_list[i][0])\n",
        "    url_len.append(ul)     \n",
        "\n",
        "\n",
        "bad_count=0\n",
        "good_count=0\n",
        "#class values    \n",
        "url_class = []\n",
        "for i in range(1,rows):\n",
        "    url_cls = ful_list[i][1]\n",
        "    if(url_cls=='malicious'): \n",
        "        url_class.append(1)\n",
        "        bad_count=bad_count+1\n",
        "    else:\n",
        "        url_class.append(0)\n",
        "        good_count=good_count+1\n",
        "\n",
        "print(\"Total Legimate URLs: \",good_count)\n",
        "print(\"Total Malicious URLs: \",bad_count)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing......\n",
            "Total Legimate URLs:  35378\n",
            "Total Malicious URLs:  129988\n",
            "(165366, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11n4KBDNH_CR",
        "outputId": "238ab56a-5508-47b7-d160-7294593199ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#dataframe\n",
        "data=pd.DataFrame(\n",
        "    {'url_len': url_len,\n",
        "     'maxw_len': maxl,\n",
        "     'dots': dots,\n",
        "     'domain_len' : len_dom,\n",
        "     'numeric_count': num_count,\n",
        "     'no_/' : slash,\n",
        "     'spcl_char': spcl,\n",
        "     '.exe_install': exe,\n",
        "     '.com': com,\n",
        "     '.php': php,\n",
        "     '.gov': gov,\n",
        "     '.org': org,\n",
        "     '.edu': edu,\n",
        "     'https': https,\n",
        "     '.htm_html': htmlt,\n",
        "     #'.txt': text,\n",
        "     '.net': net,\n",
        "     '.info': info,\n",
        "     '.js': js,\n",
        "     'q_?': qs_mark,\n",
        "     'tempt_word' : tempt,\n",
        "     'offensive': offens,\n",
        "     #'watch': watch,\n",
        "     'youtube': youtube,\n",
        "     #'image': image,\n",
        "     'login_upload' :login_upload,\n",
        "     'IP' : ip_dom,\n",
        "     'URL_Class': url_class\n",
        "     \n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "data_sape=data.shape\n",
        "print(data_sape)\n",
        "\n",
        "\n",
        "X = data.iloc[:, 0:(data_sape[1]-1)].values\n",
        "y = data.iloc[:, (data_sape[1]-1)].values\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.fit_transform(x_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(165366, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHtTvn297dvb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5CIl75hg6R7",
        "outputId": "6b50b3d0-f801-48f6-ad75-9351a5e73b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#y_train\n",
        "TR_bad_count=0\n",
        "TR_good_count=0\n",
        "for i in range(0,len(y_train)):\n",
        "    cls = y_train[i]\n",
        "    if(cls==1): \n",
        "      TR_bad_count=TR_bad_count+1\n",
        "    else:\n",
        "      TR_good_count=TR_good_count+1\n",
        "print(\"Total dataset : \",len(data))\n",
        "print(\"Total training dataset : \",len(y_train))\n",
        "print(\"Total Legimate URLs training dataset : \",TR_good_count)\n",
        "print(\"Total Malicious URLs training dataset: \",TR_bad_count)\n",
        "\n",
        "\n",
        "#y_test\n",
        "TE_bad_count=0\n",
        "TE_good_count=0\n",
        "for i in range(0,len(y_test)):\n",
        "    cls = y_test[i]\n",
        "    if(cls==1): \n",
        "      TE_bad_count=TE_bad_count+1\n",
        "    else:\n",
        "      TE_good_count=TE_good_count+1\n",
        "\n",
        "print(\"Total testing dataset : \",len(y_test))\n",
        "print(\"Total Legimate URLs testing dataset : \",TE_good_count)\n",
        "print(\"Total Malicious URLs testing dataset: \",TE_bad_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total dataset :  165366\n",
            "Total training dataset :  132292\n",
            "Total Legimate URLs training dataset :  28240\n",
            "Total Malicious URLs training dataset:  104052\n",
            "Total testing dataset :  33074\n",
            "Total Legimate URLs testing dataset :  7138\n",
            "Total Malicious URLs testing dataset:  25936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW7NW4FrHwed",
        "outputId": "cb1d4654-5112-4178-aeae-e28e2b9209ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#SVM\n",
        "\n",
        "# Load libraries\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "#Gaussian Kernel\n",
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(x_train, y_train)\n",
        "y_pred = svclassifier.predict(x_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9799842776803531\n",
            "[[ 6875   237]\n",
            " [  425 25537]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      7112\n",
            "           1       0.99      0.98      0.99     25962\n",
            "\n",
            "    accuracy                           0.98     33074\n",
            "   macro avg       0.97      0.98      0.97     33074\n",
            "weighted avg       0.98      0.98      0.98     33074\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdQqztfuIR5U",
        "outputId": "39d4544b-e540-4ebc-f139-0e538c67ccf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "#target_names = ['True', 'False']\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Creating the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      7138\n",
            "           1       1.00      1.00      1.00     25936\n",
            "\n",
            "    accuracy                           0.99     33074\n",
            "   macro avg       0.99      0.99      0.99     33074\n",
            "weighted avg       0.99      0.99      0.99     33074\n",
            "\n",
            "Accuracy: 0.9947390699643224\n",
            "[[ 7049    89]\n",
            " [   85 25851]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsG771nlgp3l",
        "outputId": "4283b272-35d0-4341-e766-24d306b93cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        " \n",
        "\n",
        "logmodel = LogisticRegression()\n",
        "logmodel.fit(x_train, y_train)\n",
        " \n",
        "predictions = logmodel.predict(x_test)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.79      0.82      7112\n",
            "           1       0.94      0.96      0.95     25962\n",
            "\n",
            "    accuracy                           0.92     33074\n",
            "   macro avg       0.89      0.88      0.88     33074\n",
            "weighted avg       0.92      0.92      0.92     33074\n",
            "\n",
            "[[ 5649  1463]\n",
            " [ 1054 24908]]\n",
            "0.9238979258632158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz6ul-mWhzQD",
        "outputId": "4a4f4108-1d90-4692-df24-3b0feb36843c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clf=RandomForestClassifier(n_estimators=50)\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "target_names = ['True', 'False']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Creating the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.99      0.99      0.99      7112\n",
            "       False       1.00      1.00      1.00     25962\n",
            "\n",
            "    accuracy                           1.00     33074\n",
            "   macro avg       1.00      1.00      1.00     33074\n",
            "weighted avg       1.00      1.00      1.00     33074\n",
            "\n",
            "Accuracy: 0.9972788292918909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7073,    39],\n",
              "       [   51, 25911]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkaDTy1LcP9s",
        "outputId": "73875636-abe7-4b29-aa48-d2a85c268b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "optimizer1=keras.optimizers.Adam(lr=0.002)\n",
        "#create model\n",
        "model = Sequential()\n",
        "\n",
        "#get number of columns in training data\n",
        "n_cols = x_train.shape[1]\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "#set early stopping monitor so the model stops training when it won't improve anymore\n",
        "early_stopping_monitor = EarlyStopping(patience=10)\n",
        "\n",
        "\n",
        "#create model\n",
        "model_mc = Sequential()\n",
        "\n",
        "#add model layers\n",
        "model_mc.add(Dense(27, activation='relu', input_shape=(n_cols,)))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(1))\n",
        "\n",
        "#compile model using mse as a measure of model performance\n",
        "model_mc.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "#train model\n",
        "model_mc.fit(x_train, y_train, validation_split=0.2, epochs=300, callbacks=[early_stopping_monitor])\n",
        "#model_mc.fit(x_train, y_train, validation_split=0.2, epochs=30)\n",
        "\n",
        "\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = model_mc.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Creating the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0348 - val_loss: 0.0193\n",
            "Epoch 2/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0139 - val_loss: 0.0124\n",
            "Epoch 3/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0109 - val_loss: 0.0108\n",
            "Epoch 4/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0094 - val_loss: 0.0090\n",
            "Epoch 5/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0082 - val_loss: 0.0088\n",
            "Epoch 6/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0077 - val_loss: 0.0081\n",
            "Epoch 7/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0072\n",
            "Epoch 8/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0064 - val_loss: 0.0075\n",
            "Epoch 9/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0059 - val_loss: 0.0074\n",
            "Epoch 10/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0058 - val_loss: 0.0066\n",
            "Epoch 11/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0053 - val_loss: 0.0077\n",
            "Epoch 12/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0055 - val_loss: 0.0058\n",
            "Epoch 13/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0052 - val_loss: 0.0099\n",
            "Epoch 14/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0049 - val_loss: 0.0121\n",
            "Epoch 15/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0048 - val_loss: 0.0056\n",
            "Epoch 16/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0046 - val_loss: 0.0059\n",
            "Epoch 17/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0043 - val_loss: 0.0059\n",
            "Epoch 18/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0043 - val_loss: 0.0057\n",
            "Epoch 19/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0042 - val_loss: 0.0078\n",
            "Epoch 20/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0043 - val_loss: 0.0061\n",
            "Epoch 21/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0042 - val_loss: 0.0049\n",
            "Epoch 22/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0039 - val_loss: 0.0050\n",
            "Epoch 23/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0037 - val_loss: 0.0069\n",
            "Epoch 24/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0040 - val_loss: 0.0053\n",
            "Epoch 25/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0037 - val_loss: 0.0050\n",
            "Epoch 26/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0038 - val_loss: 0.0054\n",
            "Epoch 27/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0035 - val_loss: 0.0047\n",
            "Epoch 28/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0036 - val_loss: 0.0060\n",
            "Epoch 29/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0035 - val_loss: 0.0050\n",
            "Epoch 30/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0034 - val_loss: 0.0050\n",
            "Epoch 31/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0035 - val_loss: 0.0055\n",
            "Epoch 32/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0034 - val_loss: 0.0050\n",
            "Epoch 33/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0032 - val_loss: 0.0053\n",
            "Epoch 34/300\n",
            "3308/3308 [==============================] - 5s 2ms/step - loss: 0.0033 - val_loss: 0.0042\n",
            "Epoch 35/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0032 - val_loss: 0.0054\n",
            "Epoch 36/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0032 - val_loss: 0.0051\n",
            "Epoch 37/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0031 - val_loss: 0.0054\n",
            "Epoch 38/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0031 - val_loss: 0.0044\n",
            "Epoch 39/300\n",
            "3308/3308 [==============================] - 5s 1ms/step - loss: 0.0029 - val_loss: 0.0048\n",
            "Epoch 40/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0030 - val_loss: 0.0046\n",
            "Epoch 41/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0031 - val_loss: 0.0049\n",
            "Epoch 42/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0029 - val_loss: 0.0050\n",
            "Epoch 43/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 44/300\n",
            "3308/3308 [==============================] - 4s 1ms/step - loss: 0.0028 - val_loss: 0.0046\n",
            "Accuracy: 0.9950716574953136\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      7112\n",
            "           1       1.00      1.00      1.00     25962\n",
            "\n",
            "    accuracy                           1.00     33074\n",
            "   macro avg       0.99      0.99      0.99     33074\n",
            "weighted avg       1.00      1.00      1.00     33074\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7049,    63],\n",
              "       [  100, 25862]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP_nTEHQMJ20"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX7WM-8mcm3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}