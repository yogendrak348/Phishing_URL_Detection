{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_url_detection",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx_J4Bsdu8xQ",
        "outputId": "3f6638e7-c4d2-4068-e8e9-9826b0f507d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import xlrd \n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "import pylab as plt\n",
        "\n",
        "\n",
        "\n",
        "# Setting Path of File and Initializing List:\n",
        "location = (\"kaggle_sep.xlsx\") \n",
        "list1 = []\n",
        "\n",
        "# Opening the Workbook and Defining Which Sheet to Use:\n",
        "wb = xlrd.open_workbook(location) \n",
        "sheet = wb.sheet_by_index(0) \n",
        "\n",
        "# Starting at Row 0 and Column 0:\n",
        "sheet.cell_value(0, 0)\n",
        "\n",
        "rows, cols = (420465, 10) \n",
        "\n",
        "# Iterating Over the Number of Rows and Appending to List:\n",
        "for i in range(0, rows):\n",
        "    list1.append(sheet.row_values(i))\n",
        "\n",
        "\n",
        "\n",
        "#maximum lengh of word in list in every row \n",
        "maxl = []\n",
        "for i in range(1,rows):\n",
        "    max1=0\n",
        "    for j in range(cols):\n",
        "        sr1=list1[i][j]\n",
        "        if(type(sr1)==float):\n",
        "          max1=1\n",
        "        elif(type(sr1)==int):\n",
        "          max1=1\n",
        "        else:\n",
        "            ml1=len(list1[i][j])\n",
        "            if(ml1>max1):\n",
        "                max1=ml1 \n",
        "    maxl.append(max1)\n",
        "\n",
        "#length of domain name\n",
        "len_dom= []\n",
        "for i in range(1,rows):\n",
        "    sr1=list1[i][0]\n",
        "    ld1=0\n",
        "    if(type(sr1)==float):\n",
        "      ld1=len(str(sr1))\n",
        "    elif(type(sr1)==int):\n",
        "      ld1=len(str(sr1))\n",
        "    else:\n",
        "      ld1 = len(sr1) \n",
        "    len_dom.append(ld1)        \n",
        "\n",
        "#ip or domain\n",
        "ip_dom= []   \n",
        "for i in range(1,rows):\n",
        "    ur1=list1[i][0]\n",
        "    if(type(ur1)==float):\n",
        "        ip_dom.append(1)\n",
        "    else:\n",
        "        ip_dom.append(0)           \n",
        "    \n",
        "   \n",
        "# Setting Path of File and Initializing List:\n",
        "location = (\"kaggle_full.xlsx\") \n",
        "ful_list = []\n",
        "\n",
        "# Opening the Workbook and Defining Which Sheet to Use:\n",
        "wb = xlrd.open_workbook(location) \n",
        "sheet = wb.sheet_by_index(0) \n",
        "\n",
        "# Starting at Row 0 and Column 0:\n",
        "sheet.cell_value(0, 0)\n",
        "\n",
        "# Iterating Over the Number of Rows and Appending to List:\n",
        "for i in range(0, rows):\n",
        "    ful_list.append(sheet.row_values(i))\n",
        "\n",
        "dots=[]\n",
        "slash=[]\n",
        "spcl=[]\n",
        "exe=[]\n",
        "\n",
        "\n",
        "for i in range(1,rows):\n",
        "    dt = ful_list[i][0].count(\".\")\n",
        "    dots.append(dt)\n",
        "\n",
        "for i in range(1,rows):\n",
        "    ss = ful_list[i][0].count(\"/\")\n",
        "    slash.append(ss)\n",
        "\n",
        "for i in range(1,rows):\n",
        "    exe_count=0\n",
        "    ex = ful_list[i][0].count(\"exe\")\n",
        "    exe_count = exe_count+ex\n",
        "    ins = ful_list[i][0].count(\"install\")\n",
        "    exe_count = exe_count+ins\n",
        "    exe.append(exe_count)\n",
        "    \n",
        "tempt=[]    \n",
        "for i in range(1,rows):\n",
        "    temp_count=0\n",
        "    temp1 = ful_list[i][0].count(\"free\")\n",
        "    temp_count= temp_count+temp1\n",
        "    temp2 = ful_list[i][0].count(\"money\")\n",
        "    temp_count= temp_count+temp2\n",
        "    temp3 = ful_list[i][0].count(\"best\")\n",
        "    temp_count= temp_count+temp3\n",
        "    temp4 = ful_list[i][0].count(\"game\")\n",
        "    temp_count= temp_count+temp4\n",
        "    tempt.append(temp_count)\n",
        "\n",
        "https=[]\n",
        "for i in range(1,rows):\n",
        "    htt1 = ful_list[i][0].count(\"https\")\n",
        "    https.append(htt1)  \n",
        "\n",
        "htmlt=[]\n",
        "for i in range(1,rows):\n",
        "    ht_count=0\n",
        "    ht1=ful_list[i][0].count(\".htm\")\n",
        "    ht_count=ht_count+ht1\n",
        "    ht2=ful_list[i][0].count(\".html\")\n",
        "    ht_count=ht_count+ht2\n",
        "    htmlt.append(ht_count)\n",
        "\n",
        "php=[]\n",
        "for i in range(1,rows):\n",
        "    ph1 = ful_list[i][0].count(\".php\")\n",
        "    php.append(ph1)\n",
        "    \n",
        "com=[]\n",
        "for i in range(1,rows):\n",
        "    co1 = ful_list[i][0].count(\".com\")\n",
        "    com.append(co1)\n",
        "    \n",
        "gov=[]\n",
        "for i in range(1,rows):\n",
        "    go1 = ful_list[i][0].count(\".gov\")\n",
        "    gov.append(go1)\n",
        "    \n",
        "edu=[]\n",
        "for i in range(1,rows):\n",
        "    ed1 = ful_list[i][0].count(\".edu\")\n",
        "    edu.append(ed1)\n",
        "    \n",
        "org=[]\n",
        "for i in range(1,rows):\n",
        "    or1 = ful_list[i][0].count(\".org\")\n",
        "    org.append(or1)\n",
        "    \n",
        "text=[]\n",
        "for i in range(1,rows):\n",
        "    tx = ful_list[i][0].count(\".txt\")\n",
        "    text.append(tx)\n",
        "\n",
        "net=[]\n",
        "for i in range(1,rows):\n",
        "    nt = ful_list[i][0].count(\".net\")\n",
        "    net.append(nt)\n",
        "\n",
        "info=[]\n",
        "for i in range(1,rows):\n",
        "    inf = ful_list[i][0].count(\".info\")\n",
        "    info.append(inf)\n",
        "    \n",
        "js=[]\n",
        "for i in range(1,rows):    \n",
        "    js1 = ful_list[i][0].count(\".js\")\n",
        "    js.append(js1)\n",
        "    \n",
        "offens=[]\n",
        "for i in range(1,rows): \n",
        "    offens_count=0\n",
        "    off1 = ful_list[i][0].count(\"girl\")\n",
        "    offens_count=offens_count+off1\n",
        "    off2 = ful_list[i][0].count(\"hot\")\n",
        "    offens_count=offens_count+off2\n",
        "    off3 = ful_list[i][0].count(\"nude\")\n",
        "    offens_count=offens_count+off3\n",
        "    off4 = ful_list[i][0].count(\"ball\")\n",
        "    offens_count=offens_count+off4\n",
        "    off5 = ful_list[i][0].count(\"sex\")\n",
        "    offens_count=offens_count+off5\n",
        "    off6 = ful_list[i][0].count(\"fuck\")\n",
        "    offens_count=offens_count+off6\n",
        "    off7 = ful_list[i][0].count(\"xx\")\n",
        "    offens_count=offens_count+off7\n",
        "    offens.append(offens_count)\n",
        "\n",
        "qs_mark=[]\n",
        "for i in range(1,rows):    \n",
        "    qs = ful_list[i][0].count(\"?\")\n",
        "    qs_mark.append(qs)\n",
        "    \n",
        "    \n",
        "for i in range(1,rows):\n",
        "    sp_count=0\n",
        "    sp1=ful_list[i][0].count(\"@\")\n",
        "    sp_count=sp_count+sp1\n",
        "    sp2=ful_list[i][0].count(\"_\")\n",
        "    sp_count=sp_count+sp2\n",
        "    sp3=ful_list[i][0].count(\"=\")\n",
        "    sp_count=sp_count+sp3\n",
        "    sp4=ful_list[i][0].count(\"#\")\n",
        "    sp_count=sp_count+sp4\n",
        "    sp5=ful_list[i][0].count(\"&\")\n",
        "    sp_count=sp_count+sp5\n",
        "    sp6=ful_list[i][0].count(\"!\")\n",
        "    sp_count=sp_count+sp6\n",
        "    sp7=ful_list[i][0].count(\"$\")\n",
        "    sp_count=sp_count+sp7\n",
        "    sp8=ful_list[i][0].count(\"%\")\n",
        "    sp_count=sp_count+sp8\n",
        "    sp9=ful_list[i][0].count(\"^\")\n",
        "    sp_count=sp_count+sp9\n",
        "    sp10=ful_list[i][0].count(\"*\")\n",
        "    sp_count=sp_count+sp10\n",
        "    sp11=ful_list[i][0].count(\"^\")\n",
        "    sp_count=sp_count+sp11\n",
        "    sp12=ful_list[i][0].count(\"*\")\n",
        "    sp_count=sp_count+sp12\n",
        "    sp13=ful_list[i][0].count(\"-\")\n",
        "    sp_count=sp_count+sp13\n",
        "    sp14=ful_list[i][0].count(\"+\")\n",
        "    sp_count=sp_count+sp14\n",
        "    spcl.append(sp_count)\n",
        "\n",
        "watch=[]\n",
        "for i in range(1,rows):\n",
        "    wat = ful_list[i][0].count(\"watch\")\n",
        "    watch.append(wat)\n",
        "    \n",
        "youtube=[]\n",
        "for i in range(1,rows):\n",
        "    you = ful_list[i][0].count(\"youtube\")\n",
        "    youtube.append(you)\n",
        "    \n",
        "image=[]\n",
        "for i in range(1,rows):\n",
        "    ima = ful_list[i][0].count(\"image\")\n",
        "    image.append(ima)\n",
        "\n",
        "login_upload=[]\n",
        "for i in range(1,rows): \n",
        "    login_count=0\n",
        "    log1 = ful_list[i][0].count(\"login\")\n",
        "    login_count=login_count+log1\n",
        "    log2 = ful_list[i][0].count(\"upload\")\n",
        "    login_count=login_count+log2\n",
        "    login_upload.append(login_count)\n",
        "    \n",
        "# no of digits count\n",
        "num_count=[]\n",
        "for i in range(1,rows):\n",
        "    digi=alfa=0\n",
        "    ulstr=ful_list[i][0]\n",
        "    for c in ulstr:\n",
        "        if c.isdigit():\n",
        "            digi=digi+1\n",
        "        else:\n",
        "            pass\n",
        "    num_count.append(digi)\n",
        "    \n",
        "url_len=[]\n",
        "for i in range(1,rows):\n",
        "    ul = len(ful_list[i][0])\n",
        "    url_len.append(ul)     \n",
        "\n",
        "\n",
        "bad_count=0\n",
        "good_count=0\n",
        "#class values    \n",
        "url_class = []\n",
        "for i in range(1,rows):\n",
        "    url_cls = ful_list[i][1]\n",
        "    if(url_cls=='bad'): \n",
        "        url_class.append(1)\n",
        "        bad_count=bad_count+1\n",
        "    else:\n",
        "        url_class.append(0)\n",
        "        good_count=good_count+1\n",
        "\n",
        "print(\"Total Legimate URLs: \",good_count)\n",
        "print(\"Total Malicious URLs: \",bad_count)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Legimate URLs:  344821\n",
            "Total Malicious URLs:  75643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHOPDe0g4wBG",
        "outputId": "d9a5dc4e-c3a8-4531-cfa9-9b80b61071d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#dataframe\n",
        "data=pd.DataFrame(\n",
        "    {'url_len': url_len,\n",
        "     'maxw_len': maxl,\n",
        "     'dots': dots,\n",
        "     'domain_len' : len_dom,\n",
        "     'numeric_count': num_count,\n",
        "     'no_/' : slash,\n",
        "     'spcl_char': spcl,\n",
        "     '.exe_install': exe,\n",
        "     '.com': com,\n",
        "     '.php': php,\n",
        "     '.gov': gov,\n",
        "     '.org': org,\n",
        "     '.edu': edu,\n",
        "     'https': https,\n",
        "     '.htm_html': htmlt,\n",
        "     #'.txt': text,\n",
        "     '.net': net,\n",
        "     '.info': info,\n",
        "     '.js': js,\n",
        "     'q_?': qs_mark,\n",
        "     'tempt_word' : tempt,\n",
        "     'offensive': offens,\n",
        "     #'watch': watch,\n",
        "     #'youtube': youtube,\n",
        "     'image': image,\n",
        "     'login_upload' :login_upload,\n",
        "     'IP' : ip_dom,\n",
        "     'URL_Class': url_class\n",
        "     \n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "data_sape=data.shape\n",
        "print(data_sape)\n",
        "\n",
        "\n",
        "X = data.iloc[:, 0:(data_sape[1]-1)].values\n",
        "y = data.iloc[:, (data_sape[1]-1)].values\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.fit_transform(x_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420464, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5CIl75hg6R7",
        "outputId": "b8a88639-da98-4619-8b13-dd8591a36071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#y_train\n",
        "TR_bad_count=0\n",
        "TR_good_count=0\n",
        "for i in range(0,len(y_train)):\n",
        "    cls = y_train[i]\n",
        "    if(cls==1): \n",
        "      TR_bad_count=TR_bad_count+1\n",
        "    else:\n",
        "      TR_good_count=TR_good_count+1\n",
        "print(\"Total dataset : \",len(data))\n",
        "print(\"Total training dataset : \",len(y_train))\n",
        "print(\"Total Legimate URLs training dataset : \",TR_good_count)\n",
        "print(\"Total Malicious URLs training dataset: \",TR_bad_count)\n",
        "\n",
        "\n",
        "#y_test\n",
        "TE_bad_count=0\n",
        "TE_good_count=0\n",
        "for i in range(0,len(y_test)):\n",
        "    cls = y_test[i]\n",
        "    if(cls==1): \n",
        "      TE_bad_count=TE_bad_count+1\n",
        "    else:\n",
        "      TE_good_count=TE_good_count+1\n",
        "\n",
        "print(\"Total testing dataset : \",len(y_test))\n",
        "print(\"Total Legimate URLs testing dataset : \",TE_good_count)\n",
        "print(\"Total Malicious URLs testing dataset: \",TE_bad_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total dataset :  420464\n",
            "Total training dataset :  336371\n",
            "Total Legimate URLs training dataset :  275775\n",
            "Total Malicious URLs training dataset:  60596\n",
            "Total testing dataset :  84093\n",
            "Total Legimate URLs testing dataset :  69046\n",
            "Total Malicious URLs testing dataset:  15047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW7NW4FrHwed",
        "outputId": "5e8d6178-a16c-45bb-a436-452acd063007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#SVM\n",
        "\n",
        "# Load libraries\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "#Gaussian Kernel\n",
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(x_train, y_train)\n",
        "y_pred = svclassifier.predict(x_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9142734829296136\n",
            "[[67760  1342]\n",
            " [ 5867  9124]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95     69102\n",
            "           1       0.87      0.61      0.72     14991\n",
            "\n",
            "    accuracy                           0.91     84093\n",
            "   macro avg       0.90      0.79      0.83     84093\n",
            "weighted avg       0.91      0.91      0.91     84093\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdQqztfuIR5U",
        "outputId": "ecca386f-a86c-4aff-db7a-4d83df2510a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "target_names = ['True', 'False']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Creating the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.95      0.97      0.96     69046\n",
            "       False       0.86      0.79      0.82     15047\n",
            "\n",
            "    accuracy                           0.94     84093\n",
            "   macro avg       0.91      0.88      0.89     84093\n",
            "weighted avg       0.94      0.94      0.94     84093\n",
            "\n",
            "Accuracy: 0.9395312332774428\n",
            "[[67139  1907]\n",
            " [ 3178 11869]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsG771nlgp3l",
        "outputId": "6a636607-6b65-4e32-ee33-8de6e8543469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        " \n",
        "\n",
        "logmodel = LogisticRegression()\n",
        "logmodel.fit(x_train, y_train)\n",
        " \n",
        "predictions = logmodel.predict(x_test)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93     69102\n",
            "           1       0.79      0.43      0.56     14991\n",
            "\n",
            "    accuracy                           0.88     84093\n",
            "   macro avg       0.84      0.70      0.74     84093\n",
            "weighted avg       0.87      0.88      0.86     84093\n",
            "\n",
            "[[67346  1756]\n",
            " [ 8478  6513]]\n",
            "0.8783014043975123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz6ul-mWhzQD",
        "outputId": "1c47702d-04c6-42fe-e400-0309fcbb8d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clf=RandomForestClassifier(n_estimators=50)\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "target_names = ['True', 'False']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Creating the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.96      0.98      0.97     69102\n",
            "       False       0.89      0.83      0.86     14991\n",
            "\n",
            "    accuracy                           0.95     84093\n",
            "   macro avg       0.93      0.90      0.91     84093\n",
            "weighted avg       0.95      0.95      0.95     84093\n",
            "\n",
            "Accuracy: 0.9507331169062824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[67567,  1535],\n",
              "       [ 2608, 12383]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkaDTy1LcP9s",
        "outputId": "8ae8be59-59d3-4bd3-d494-94051b2a36e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "optimizer1=keras.optimizers.Adam(lr=0.002)\n",
        "#create model\n",
        "model = Sequential()\n",
        "\n",
        "#get number of columns in training data\n",
        "n_cols = x_train.shape[1]\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "#set early stopping monitor so the model stops training when it won't improve anymore\n",
        "early_stopping_monitor = EarlyStopping(patience=10)\n",
        "\n",
        "\n",
        "#create model\n",
        "model_mc = Sequential()\n",
        "\n",
        "#add model layers\n",
        "model_mc.add(Dense(27, activation='relu', input_shape=(n_cols,)))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(32, activation='relu'))\n",
        "model_mc.add(Dense(1))\n",
        "\n",
        "#compile model using mse as a measure of model performance\n",
        "model_mc.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "#train model\n",
        "model_mc.fit(x_train, y_train, validation_split=0.2, epochs=300, callbacks=[early_stopping_monitor])\n",
        "#model_mc.fit(x_train, y_train, validation_split=0.2, epochs=30)\n",
        "\n",
        "\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = model_mc.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Creating the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "8410/8410 [==============================] - 17s 2ms/step - loss: 0.0731 - val_loss: 0.0623\n",
            "Epoch 2/300\n",
            "8410/8410 [==============================] - 13s 2ms/step - loss: 0.0604 - val_loss: 0.0595\n",
            "Epoch 3/300\n",
            "8410/8410 [==============================] - 13s 2ms/step - loss: 0.0575 - val_loss: 0.0550\n",
            "Epoch 4/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0559 - val_loss: 0.0548\n",
            "Epoch 5/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0549 - val_loss: 0.0541\n",
            "Epoch 6/300\n",
            "8410/8410 [==============================] - 13s 2ms/step - loss: 0.0541 - val_loss: 0.0558\n",
            "Epoch 7/300\n",
            "8410/8410 [==============================] - 13s 2ms/step - loss: 0.0534 - val_loss: 0.0557\n",
            "Epoch 8/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0529 - val_loss: 0.0546\n",
            "Epoch 9/300\n",
            "8410/8410 [==============================] - 15s 2ms/step - loss: 0.0524 - val_loss: 0.0526\n",
            "Epoch 10/300\n",
            "8410/8410 [==============================] - 22s 3ms/step - loss: 0.0519 - val_loss: 0.0552\n",
            "Epoch 11/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0516 - val_loss: 0.0523\n",
            "Epoch 12/300\n",
            "8410/8410 [==============================] - 15s 2ms/step - loss: 0.0514 - val_loss: 0.0518\n",
            "Epoch 13/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0510 - val_loss: 0.0583\n",
            "Epoch 14/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0508 - val_loss: 0.0576\n",
            "Epoch 15/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0507 - val_loss: 0.0563\n",
            "Epoch 16/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0505 - val_loss: 0.0531\n",
            "Epoch 17/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0503 - val_loss: 0.0516\n",
            "Epoch 18/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0500 - val_loss: 0.0533\n",
            "Epoch 19/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0498 - val_loss: 0.0505\n",
            "Epoch 20/300\n",
            "8410/8410 [==============================] - 13s 2ms/step - loss: 0.0496 - val_loss: 0.0520\n",
            "Epoch 21/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0496 - val_loss: 0.0516\n",
            "Epoch 22/300\n",
            "8410/8410 [==============================] - 13s 2ms/step - loss: 0.0495 - val_loss: 0.0548\n",
            "Epoch 23/300\n",
            "8410/8410 [==============================] - 16s 2ms/step - loss: 0.0492 - val_loss: 0.0518\n",
            "Epoch 24/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0492 - val_loss: 0.0517\n",
            "Epoch 25/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0490 - val_loss: 0.0514\n",
            "Epoch 26/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0488 - val_loss: 0.0653\n",
            "Epoch 27/300\n",
            "8410/8410 [==============================] - 13s 2ms/step - loss: 0.0488 - val_loss: 0.0554\n",
            "Epoch 28/300\n",
            "8410/8410 [==============================] - 14s 2ms/step - loss: 0.0487 - val_loss: 0.0519\n",
            "Epoch 29/300\n",
            "8410/8410 [==============================] - 13s 2ms/step - loss: 0.0487 - val_loss: 0.0517\n",
            "Accuracy: 0.9334070612298289\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96     69102\n",
            "           1       0.86      0.74      0.80     14991\n",
            "\n",
            "    accuracy                           0.93     84093\n",
            "   macro avg       0.91      0.86      0.88     84093\n",
            "weighted avg       0.93      0.93      0.93     84093\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[67363,  1739],\n",
              "       [ 3861, 11130]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP_nTEHQMJ20"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX7WM-8mcm3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}